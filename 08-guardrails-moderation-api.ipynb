{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8ì°¨ì‹œ ì‹¤ìŠµ: ê°€ë“œë ˆì¼ ê¸°ì´ˆ - OpenAI Moderation API í™œìš©\n",
    "\n",
    "ì´ë²ˆ ì‹œê°„ì—ëŠ” LLMì„ ì•ˆì „í•˜ê²Œ ë³´í˜¸í•˜ëŠ” ì²« ë²ˆì§¸ ê´€ë¬¸ì¸ **ê°€ë“œë ˆì¼(Guardrails)**ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "OpenAIì—ì„œ ë¬´ë£Œë¡œ ì œê³µí•˜ëŠ” `Moderation API`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì˜ ìœ í•´ì„±ì„ íŒë³„í•˜ê³ , ì ìˆ˜(Score) ê¸°ë°˜ìœ¼ë¡œ ì œì–´í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "### í•™ìŠµ ëª©í‘œ\n",
    "1. Moderation API í˜¸ì¶œ ë° JSON ì‘ë‹µ êµ¬ì¡° ë¶„ì„\n",
    "2. `Flagged`ì™€ `Score`ì˜ ì°¨ì´ì  ì´í•´ ë° ì„ê³„ê°’(Threshold) íŠœë‹\n",
    "3. ë‹¨ìˆœ ê°€ë“œë ˆì¼ì˜ í•œê³„ì (False Positive) ì²´í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install openai pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì • (Moderation APIëŠ” OpenAI ê³„ì •ì´ í•„ìš”í•©ë‹ˆë‹¤)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"API Keyë¥¼ ë„£ìœ¼ì„¸ìš”!\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def check_moderation(text):\n",
    "    \"\"\"\n",
    "    OpenAI Moderation APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìœ í•´ì„± ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    response = client.moderations.create(input=text)\n",
    "    return response.results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ê¸°ë³¸ ê²€ì‚¬: ì•ˆì „í•œ ë¬¸ì¥ vs ìœ„í—˜í•œ ë¬¸ì¥\n",
    "APIê°€ ë¬¸ì¥ì„ ì–´ë–»ê²Œ ë¶„ë¥˜í•˜ëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Safe Text] Flagged: False\n",
      "[Unsafe Text] Flagged: True\n",
      "\n",
      "--- ìœ„í—˜ ë¬¸ì¥ ìƒì„¸ ì ìˆ˜ ---\n",
      "harassment: 0.3417\n",
      "harassment/threatening: 0.3228\n",
      "illicit: 0.0947\n",
      "illicit/violent: 0.0578\n",
      "violence: 0.9430\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "safe_text = \"ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”. ì ì‹¬ ë©”ë‰´ ì¶”ì²œí•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\"\n",
    "unsafe_text = \"ì € ë…€ì„ì„ ë•Œë ¤ì£¼ê³  ì‹¶ì–´. ì•„ì£¼ ì”ì¸í•˜ê²Œ ë³µìˆ˜í•  ê±°ì•¼.\" # (êµìœ¡ìš© ì˜ˆì‹œ)\n",
    "\n",
    "# 1. ì•ˆì „í•œ ë¬¸ì¥ ê²€ì‚¬\n",
    "res_safe = check_moderation(safe_text)\n",
    "print(f\"[Safe Text] Flagged: {res_safe.flagged}\")\n",
    "\n",
    "# 2. ìœ„í—˜í•œ ë¬¸ì¥ ê²€ì‚¬\n",
    "res_unsafe = check_moderation(unsafe_text)\n",
    "print(f\"[Unsafe Text] Flagged: {res_unsafe.flagged}\")\n",
    "\n",
    "# ìƒì„¸ ì ìˆ˜ ì¶œë ¥\n",
    "print(\"\\n--- ìœ„í—˜ ë¬¸ì¥ ìƒì„¸ ì ìˆ˜ ---\")\n",
    "for category, score in res_unsafe.category_scores.to_dict().items():\n",
    "    if score > 0.01: # 0.01ì  ì´ìƒë§Œ ì¶œë ¥\n",
    "        print(f\"{category}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì„ê³„ê°’(Threshold) íŠœë‹ ì‹¤í—˜\n",
    "APIê°€ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” `flagged` ê°’ì€ ë³´ìˆ˜ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì„œë¹„ìŠ¤ ì„±ê²©ì— ë”°ë¼ ìš°ë¦¬ê°€ ì§ì ‘ ì ìˆ˜(Score)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì°¨ë‹¨ ì—¬ë¶€ë¥¼ ê²°ì •í•´ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥: 'ì´ ì˜í™” ì™„ì „ ì£½ì—¬ì£¼ë„¤! ì§„ì§œ ë¯¸ì¹œ ì•¡ì…˜ì´ì•¼!'\n",
      " -> ìµœëŒ€ ìœ„í—˜ í•­ëª©: violence (0.2037)\n",
      "ğŸš« [ì°¨ë‹¨] ê¸°ì¤€ì¹˜(0.1) ì´ˆê³¼!\n",
      "\n",
      "ì…ë ¥: 'ì´ ì˜í™” ì™„ì „ ì£½ì—¬ì£¼ë„¤! ì§„ì§œ ë¯¸ì¹œ ì•¡ì…˜ì´ì•¼!'\n",
      " -> ìµœëŒ€ ìœ„í—˜ í•­ëª©: violence (0.2037)\n",
      "âœ… [í†µê³¼] ê¸°ì¤€ì¹˜(0.8) ë¯¸ë§Œ.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_guardrail(text, threshold=0.5):\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ì ì •ì˜ ì„ê³„ê°’ì„ ì ìš©í•œ ê°€ë“œë ˆì¼ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    result = check_moderation(text)\n",
    "    scores = result.category_scores.to_dict()\n",
    "    \n",
    "    # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°\n",
    "    max_category = max(scores, key=scores.get)\n",
    "    max_score = scores[max_category]\n",
    "    \n",
    "    print(f\"ì…ë ¥: '{text}'\")\n",
    "    print(f\" -> ìµœëŒ€ ìœ„í—˜ í•­ëª©: {max_category} ({max_score:.4f})\")\n",
    "    \n",
    "    if max_score > threshold:\n",
    "        print(f\"ğŸš« [ì°¨ë‹¨] ê¸°ì¤€ì¹˜({threshold}) ì´ˆê³¼!\\n\")\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"âœ… [í†µê³¼] ê¸°ì¤€ì¹˜({threshold}) ë¯¸ë§Œ.\\n\")\n",
    "        return True\n",
    "\n",
    "# ì• ë§¤í•œ ë¬¸ì¥ í…ŒìŠ¤íŠ¸ (í­ë ¥ì„±ì´ ìˆì§€ë§Œ ë†ë‹´ì¼ ìˆ˜ ìˆëŠ” ê²½ìš°)\n",
    "ambiguous_text = \"ì´ ì˜í™” ì™„ì „ ì£½ì—¬ì£¼ë„¤! ì§„ì§œ ë¯¸ì¹œ ì•¡ì…˜ì´ì•¼!\"\n",
    "\n",
    "# 1. ì—„ê²©í•œ ê¸°ì¤€ (Strict: 0.1)\n",
    "custom_guardrail(ambiguous_text, threshold=0.1)\n",
    "\n",
    "# 2. ëŠìŠ¨í•œ ê¸°ì¤€ (Loose: 0.8)\n",
    "custom_guardrail(ambiguous_text, threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Moderation APIì˜ í•œê³„ (False Positive)\n",
    "ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ì€ **ë¬¸ë§¥(Context)**ì„ ì™„ë²½íˆ ì´í•´í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "íŠ¹íˆ IT ê¸°ìˆ  ìš©ì–´ë‚˜ ì†Œì„¤ ì°½ì‘ ìƒí™©ì—ì„œ ë°œìƒí•˜ëŠ” **ì˜¤íƒ(False Positive)** ì‚¬ë¡€ë¥¼ í™•ì¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ë¬¸ë§¥ ì˜¤í•´ í…ŒìŠ¤íŠ¸ ---\n",
      "ì…ë ¥: 'ë¦¬ëˆ…ìŠ¤ ì„œë²„ì—ì„œ ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì£½ì´ëŠ”(kill) ëª…ë ¹ì–´ë¥¼ ì•Œë ¤ì¤˜.'\n",
      " -> ìµœëŒ€ ìœ„í—˜ í•­ëª©: violence (0.4269)\n",
      "ğŸš« [ì°¨ë‹¨] ê¸°ì¤€ì¹˜(0.3) ì´ˆê³¼!\n",
      "\n",
      "ì…ë ¥: 'ì†Œì„¤ ì† ì•…ë‹¹ì´ ì£¼ì¸ê³µì„ ìœ„í˜‘í•˜ëŠ” ëŒ€ì‚¬ë¥¼ ì¨ì¤˜: 'ë„ˆë¥¼ ê°€ë§Œë‘ì§€ ì•Šê² ë‹¤.''\n",
      " -> ìµœëŒ€ ìœ„í—˜ í•­ëª©: violence (0.5250)\n",
      "ğŸš« [ì°¨ë‹¨] ê¸°ì¤€ì¹˜(0.3) ì´ˆê³¼!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IT ê¸°ìˆ  ìš©ì–´ (í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ)\n",
    "tech_context = \"ë¦¬ëˆ…ìŠ¤ ì„œë²„ì—ì„œ ì¢€ë¹„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì£½ì´ëŠ”(kill) ëª…ë ¹ì–´ë¥¼ ì•Œë ¤ì¤˜.\"\n",
    "\n",
    "# ì†Œì„¤ ì°½ì‘ ìƒí™©\n",
    "novel_context = \"ì†Œì„¤ ì† ì•…ë‹¹ì´ ì£¼ì¸ê³µì„ ìœ„í˜‘í•˜ëŠ” ëŒ€ì‚¬ë¥¼ ì¨ì¤˜: 'ë„ˆë¥¼ ê°€ë§Œë‘ì§€ ì•Šê² ë‹¤.'\"\n",
    "\n",
    "print(\"--- ë¬¸ë§¥ ì˜¤í•´ í…ŒìŠ¤íŠ¸ ---\")\n",
    "custom_guardrail(tech_context, threshold=0.3) \n",
    "custom_guardrail(novel_context, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ [Gateway] ì…ë ¥ì—ì„œ PII ê°ì§€! ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "LLM ì…ë ¥ê°’: ì œ ì£¼ë¯¼ë²ˆí˜¸ ******-*******ë¡œ ì¡°íšŒí•´ì£¼ì„¸ìš”.\n",
      "ğŸš« [Gateway] ì •ì±… ìœ„ë°˜ í‘œí˜„ ê°ì§€: 'ë¬´ì¡°ê±´ ìˆ˜ìµ'\n",
      "ì‚¬ìš©ì ì‘ë‹µ: âš ï¸ [ì°¨ë‹¨ë¨] ê¸ˆìœµì†Œë¹„ìë³´í˜¸ë²• ë° ë‚´ë¶€ ì •ì±…ì— ë”°ë¼ ì œê³µí•  ìˆ˜ ì—†ëŠ” ë‹µë³€ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class FinancialSafetyGateway:\n",
    "    def __init__(self):\n",
    "        # ê¸ˆìœµì‚¬ ê¸ˆì§€ ë‹¨ì–´/íŒ¨í„´ (ì •ê·œì‹)\n",
    "        self.blocked_patterns = [\n",
    "            r\"ë¬´ì¡°ê±´ ìˆ˜ìµ\", r\"ì›ê¸ˆ ë³´ì¥\", r\"100% ìƒìŠ¹\",  # ë¶ˆë²• íˆ¬ì ê¶Œìœ \n",
    "            r\"ë‚´ë¶€ë“±ê¸‰\", r\"íŠ¹ìˆ˜ì½”ë“œ\",                   # ë‚´ë¶€ ê¸°ë°€\n",
    "        ]\n",
    "        # PII íŒ¨í„´ (ì£¼ë¯¼ë²ˆí˜¸ ì˜ˆì‹œ)\n",
    "        self.pii_pattern = r\"\\d{6}-[1-4]\\d{6}\"\n",
    "\n",
    "    def input_filter(self, user_input: str) -> str:\n",
    "        \"\"\"ì…ë ¥ ë‹¨ê³„: PII ë§ˆìŠ¤í‚¹\"\"\"\n",
    "        if re.search(self.pii_pattern, user_input):\n",
    "            print(\"ğŸ›¡ï¸ [Gateway] ì…ë ¥ì—ì„œ PII ê°ì§€! ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "            return re.sub(self.pii_pattern, \"******-*******\", user_input)\n",
    "        return user_input\n",
    "\n",
    "    def output_filter(self, llm_response: str) -> str:\n",
    "        \"\"\"ì¶œë ¥ ë‹¨ê³„: ê¸ˆìœµ ì»´í”Œë¼ì´ì–¸ìŠ¤ ìœ„ë°˜ ê²€ì‚¬\"\"\"\n",
    "        for pattern in self.blocked_patterns:\n",
    "            if re.search(pattern, llm_response):\n",
    "                print(f\"ğŸš« [Gateway] ì •ì±… ìœ„ë°˜ í‘œí˜„ ê°ì§€: '{pattern}'\")\n",
    "                return \"âš ï¸ [ì°¨ë‹¨ë¨] ê¸ˆìœµì†Œë¹„ìë³´í˜¸ë²• ë° ë‚´ë¶€ ì •ì±…ì— ë”°ë¼ ì œê³µí•  ìˆ˜ ì—†ëŠ” ë‹µë³€ì…ë‹ˆë‹¤.\"\n",
    "        return llm_response\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ ---\n",
    "gateway = FinancialSafetyGateway()\n",
    "\n",
    "# 1. ì…ë ¥ í•„í„° í…ŒìŠ¤íŠ¸ (PII)\n",
    "user_query = \"ì œ ì£¼ë¯¼ë²ˆí˜¸ 900101-1234567ë¡œ ì¡°íšŒí•´ì£¼ì„¸ìš”.\"\n",
    "safe_query = gateway.input_filter(user_query)\n",
    "print(f\"LLM ì…ë ¥ê°’: {safe_query}\")\n",
    "\n",
    "# 2. ì¶œë ¥ í•„í„° í…ŒìŠ¤íŠ¸ (ë¶ˆë²• ê¶Œìœ )\n",
    "unsafe_response = \"ì´ ìƒí’ˆì€ ë¬´ì¡°ê±´ ìˆ˜ìµì´ ë‚˜ëŠ” í™•ì‹¤í•œ ì¢…ëª©ì…ë‹ˆë‹¤.\"\n",
    "final_output = gateway.output_filter(unsafe_response)\n",
    "print(f\"ì‚¬ìš©ì ì‘ë‹µ: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LLM ê°€ë“œë ˆì¼ ì„±ëŠ¥ í‰ê°€ (3ê°€ì§€ ë°©ì‹ ë¹„êµ)\n",
      "================================================================================\n",
      "\n",
      "[ë°©ì‹ 1] íŒ¨í„´ í•„í„° + LLM API\n",
      "--------------------------------------------------------------------------------\n",
      "ì •ìƒ ìš”ì²­           â†’  1918.58ms (íŒ¨í„´: 0.02ms + LLM: 1918.53ms + íŒ¨í„´: 0.03ms)\n",
      "ğŸ›¡ï¸ [Gateway] ì…ë ¥ì—ì„œ PII ê°ì§€! ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "PII í¬í•¨          â†’  1548.26ms (íŒ¨í„´: 0.05ms + LLM: 1548.19ms + íŒ¨í„´: 0.02ms)\n",
      "ì •ì±… ìœ„ë°˜           â†’  1184.91ms (íŒ¨í„´: 0.01ms + LLM: 1184.88ms + íŒ¨í„´: 0.02ms)\n",
      "\n",
      "[ë°©ì‹ 2] LLM API (ê°€ë“œë ˆì¼ ì—†ìŒ)\n",
      "--------------------------------------------------------------------------------\n",
      "ì •ìƒ ìš”ì²­           â†’  1635.16ms (LLM: 1635.16ms)\n",
      "PII í¬í•¨          â†’  1026.23ms (LLM: 1026.23ms)\n",
      "ì •ì±… ìœ„ë°˜           â†’   876.29ms (LLM: 876.29ms)\n",
      "\n",
      "[ë°©ì‹ 3] íŒ¨í„´ í•„í„° + Moderation + LLM + íŒ¨í„´ í•„í„° + Moderation\n",
      "--------------------------------------------------------------------------------\n",
      "ì •ìƒ ìš”ì²­           â†’  2342.04ms (ì…ë ¥íŒ¨í„´: 0.02ms + ì…ë ¥API: 259.99ms + LLM: 1673.84ms + ì¶œë ¥íŒ¨í„´: 0.02ms + ì¶œë ¥API: 408.18ms)\n",
      "ğŸ›¡ï¸ [Gateway] ì…ë ¥ì—ì„œ PII ê°ì§€! ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "PII í¬í•¨          â†’  2473.87ms (ì…ë ¥íŒ¨í„´: 0.04ms + ì…ë ¥API: 309.06ms + LLM: 817.58ms + ì¶œë ¥íŒ¨í„´: 0.02ms + ì¶œë ¥API: 1347.18ms)\n",
      "ì •ì±… ìœ„ë°˜           â†’  1832.07ms (ì…ë ¥íŒ¨í„´: 0.01ms + ì…ë ¥API: 467.87ms + LLM: 1038.51ms + ì¶œë ¥íŒ¨í„´: 0.02ms + ì¶œë ¥API: 325.67ms)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "ë°©ì‹      íŒ¨í„´ í•„í„° + LLM    LLMë§Œ ì‚¬ìš©    ì „ì²´ ê°€ë“œë ˆì¼\n",
      "ì¹´í…Œê³ ë¦¬                                     \n",
      "PII í¬í•¨    1548.2633  1026.2315  2473.8671\n",
      "ì •ìƒ ìš”ì²­     1918.5799  1635.1555  2342.0420\n",
      "ì •ì±… ìœ„ë°˜     1184.9079   876.2915  1832.0747\n",
      "\n",
      "================================================================================\n",
      "í‰ê· ê°’ ë¹„êµ\n",
      "================================================================================\n",
      "\n",
      "ë°©ì‹\n",
      "íŒ¨í„´ í•„í„° + LLM    1550.583700\n",
      "LLMë§Œ ì‚¬ìš©        1179.226167\n",
      "ì „ì²´ ê°€ë“œë ˆì¼        2215.994600\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "class HybridSafetyGateway(FinancialSafetyGateway):\n",
    "    \"\"\"íŒ¨í„´ ê¸°ë°˜ í•„í„° + Moderation APIë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê°€ë“œë ˆì¼\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.client = client\n",
    "        \n",
    "    def check_moderation_api(self, text: str) -> dict:\n",
    "        \"\"\"Moderation API í˜¸ì¶œ\"\"\"\n",
    "        try:\n",
    "            response = self.client.moderations.create(input=text)\n",
    "            return {\n",
    "                \"flagged\": response.results[0].flagged,\n",
    "                \"scores\": response.results[0].category_scores.to_dict()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    \n",
    "    def call_llm(self, text: str) -> str:\n",
    "        \"\"\"LLM API í˜¸ì¶œ (ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±)\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": text}],\n",
    "                max_tokens=50,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    # --- 1. íŒ¨í„´ í•„í„° + LLM API ---\n",
    "    def pattern_then_llm(self, user_input: str) -> tuple[bool, str, dict]:\n",
    "        \"\"\"íŒ¨í„´ í•„í„° ì ìš© í›„ LLM í˜¸ì¶œ\"\"\"\n",
    "        timing = {}\n",
    "        \n",
    "        # ì…ë ¥ íŒ¨í„´ í•„í„°\n",
    "        start = time.perf_counter()\n",
    "        processed = self.input_filter(user_input)\n",
    "        timing[\"input_pattern_filter_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # LLM í˜¸ì¶œ\n",
    "        start = time.perf_counter()\n",
    "        llm_response = self.call_llm(processed)\n",
    "        timing[\"llm_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # ì¶œë ¥ íŒ¨í„´ í•„í„°\n",
    "        start = time.perf_counter()\n",
    "        final_output = self.output_filter(llm_response)\n",
    "        timing[\"output_pattern_filter_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        timing[\"total_ms\"] = sum([v for k, v in timing.items() if \"ms\" in k])\n",
    "        return True, final_output, timing\n",
    "\n",
    "    # --- 2. LLM APIë§Œ ì‚¬ìš© (ê°€ë“œë ˆì¼ ì—†ìŒ) ---\n",
    "    def llm_only(self, user_input: str) -> tuple[str, dict]:\n",
    "        \"\"\"LLMë§Œ í˜¸ì¶œ (ê°€ë“œë ˆì¼ ì—†ìŒ)\"\"\"\n",
    "        timing = {}\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        llm_response = self.call_llm(user_input)\n",
    "        timing[\"llm_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        timing[\"total_ms\"] = timing[\"llm_ms\"]\n",
    "        \n",
    "        return llm_response, timing\n",
    "\n",
    "    # --- 3. ëª¨ë“  ê°€ë“œë ˆì¼ ì ìš© (íŒ¨í„´ + Moderation + LLM) ---\n",
    "    def full_pipeline(self, user_input: str) -> tuple[str, dict]:\n",
    "        \"\"\"ëª¨ë“  ê°€ë“œë ˆì¼ ì ìš©: íŒ¨í„´í•„í„° â†’ Moderation â†’ LLM â†’ íŒ¨í„´í•„í„° â†’ Moderation\"\"\"\n",
    "        timing = {}\n",
    "        \n",
    "        # ì…ë ¥ íŒ¨í„´ í•„í„°\n",
    "        start = time.perf_counter()\n",
    "        processed = self.input_filter(user_input)\n",
    "        timing[\"input_pattern_filter_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # ì…ë ¥ Moderation API\n",
    "        start = time.perf_counter()\n",
    "        mod_result = self.check_moderation_api(processed)\n",
    "        timing[\"input_moderation_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # LLM í˜¸ì¶œ\n",
    "        start = time.perf_counter()\n",
    "        llm_response = self.call_llm(processed)\n",
    "        timing[\"llm_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # ì¶œë ¥ íŒ¨í„´ í•„í„°\n",
    "        start = time.perf_counter()\n",
    "        checked = self.output_filter(llm_response)\n",
    "        timing[\"output_pattern_filter_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        # ì¶œë ¥ Moderation API\n",
    "        start = time.perf_counter()\n",
    "        out_mod_result = self.check_moderation_api(checked)\n",
    "        timing[\"output_moderation_ms\"] = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        timing[\"total_ms\"] = sum([v for k, v in timing.items() if \"ms\" in k])\n",
    "        return checked, timing\n",
    "\n",
    "# --- ë²¤ì¹˜ë§ˆí¬ ---\n",
    "print(\"=\" * 80)\n",
    "print(\"LLM ê°€ë“œë ˆì¼ ì„±ëŠ¥ í‰ê°€ (3ê°€ì§€ ë°©ì‹ ë¹„êµ)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "gateway_hybrid = HybridSafetyGateway()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤\n",
    "test_cases = [\n",
    "    (\"ì •ìƒ ìš”ì²­\", \"ì£¼ì‹ íˆ¬ì ì‹œ ì£¼ì˜ì‚¬í•­ì„ ì•Œë ¤ì¤˜\"),\n",
    "    (\"PII í¬í•¨\", \"ë‚´ ì£¼ë¯¼ë²ˆí˜¸ 900101-1234567ë¡œ ê³„ì¢Œë¥¼ ì¡°íšŒí•´ì¤˜\"),\n",
    "    (\"ì •ì±… ìœ„ë°˜\", \"ì´ ìƒí’ˆì€ ë¬´ì¡°ê±´ ìˆ˜ìµì´ ë‚˜ëŠ” í™•ì‹¤í•œ ì¢…ëª©ì…ë‹ˆë‹¤.\"),\n",
    "]\n",
    "\n",
    "results_data = []\n",
    "\n",
    "print(\"\\n[ë°©ì‹ 1] íŒ¨í„´ í•„í„° + LLM API\")\n",
    "print(\"-\" * 80)\n",
    "for category, text in test_cases:\n",
    "    _, output, timing = gateway_hybrid.pattern_then_llm(text)\n",
    "    print(f\"{category:<15} â†’ {timing['total_ms']:>8.2f}ms (íŒ¨í„´: {timing['input_pattern_filter_ms']:.2f}ms + LLM: {timing['llm_ms']:.2f}ms + íŒ¨í„´: {timing['output_pattern_filter_ms']:.2f}ms)\")\n",
    "    results_data.append({\n",
    "        \"ë°©ì‹\": \"íŒ¨í„´ í•„í„° + LLM\",\n",
    "        \"ì¹´í…Œê³ ë¦¬\": category,\n",
    "        \"ì´í•©(ms)\": timing['total_ms']\n",
    "    })\n",
    "\n",
    "print(\"\\n[ë°©ì‹ 2] LLM API (ê°€ë“œë ˆì¼ ì—†ìŒ)\")\n",
    "print(\"-\" * 80)\n",
    "for category, text in test_cases:\n",
    "    output, timing = gateway_hybrid.llm_only(text)\n",
    "    print(f\"{category:<15} â†’ {timing['total_ms']:>8.2f}ms (LLM: {timing['llm_ms']:.2f}ms)\")\n",
    "    results_data.append({\n",
    "        \"ë°©ì‹\": \"LLMë§Œ ì‚¬ìš©\",\n",
    "        \"ì¹´í…Œê³ ë¦¬\": category,\n",
    "        \"ì´í•©(ms)\": timing['total_ms']\n",
    "    })\n",
    "\n",
    "print(\"\\n[ë°©ì‹ 3] íŒ¨í„´ í•„í„° + Moderation + LLM + íŒ¨í„´ í•„í„° + Moderation\")\n",
    "print(\"-\" * 80)\n",
    "for category, text in test_cases:\n",
    "    output, timing = gateway_hybrid.full_pipeline(text)\n",
    "    print(f\"{category:<15} â†’ {timing['total_ms']:>8.2f}ms (ì…ë ¥íŒ¨í„´: {timing['input_pattern_filter_ms']:.2f}ms + ì…ë ¥API: {timing['input_moderation_ms']:.2f}ms + LLM: {timing['llm_ms']:.2f}ms + ì¶œë ¥íŒ¨í„´: {timing['output_pattern_filter_ms']:.2f}ms + ì¶œë ¥API: {timing['output_moderation_ms']:.2f}ms)\")\n",
    "    results_data.append({\n",
    "        \"ë°©ì‹\": \"ì „ì²´ ê°€ë“œë ˆì¼\",\n",
    "        \"ì¹´í…Œê³ ë¦¬\": category,\n",
    "        \"ì´í•©(ms)\": timing['total_ms']\n",
    "    })\n",
    "\n",
    "# ê²°ê³¼ í…Œì´ë¸”\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "# ë°©ì‹ë³„ë¡œ í”¼ë²—\n",
    "pivot_table = df_results.pivot(index=\"ì¹´í…Œê³ ë¦¬\", columns=\"ë°©ì‹\", values=\"ì´í•©(ms)\")\n",
    "pivot_table = pivot_table[[\"íŒ¨í„´ í•„í„° + LLM\", \"LLMë§Œ ì‚¬ìš©\", \"ì „ì²´ ê°€ë“œë ˆì¼\"]]\n",
    "print(\"\\n\" + pivot_table.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"í‰ê· ê°’ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "avg_summary = df_results.groupby(\"ë°©ì‹\")[\"ì´í•©(ms)\"].mean()\n",
    "avg_summary = avg_summary[[\"íŒ¨í„´ í•„í„° + LLM\", \"LLMë§Œ ì‚¬ìš©\", \"ì „ì²´ ê°€ë“œë ˆì¼\"]]\n",
    "print(\"\\n\" + avg_summary.to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
