{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3-3. 간단한 보상 점수 실험 (naver-news-dpo)\n",
        "\n",
        "이 노트북에서는 Hugging Face의 `dev7halo/naver-news-dpo` 데이터셋을 활용해서\n",
        "\n",
        "- 실제 DPO(선호 학습) 데이터 구조를 확인하고\n",
        "- 직접 **A/B 중 더 좋은 답변을 선택**해 보고\n",
        "- 그 결과를 **원래 데이터의 preference(chosen)** 과 비교합니다.\n",
        "\n",
        "이 과정을 통해,\n",
        "\n",
        "> *\"사람 선호 → 보상 점수(Reward) → 모델 학습\"*\n",
        "\n",
        "이라는 Alignment의 핵심 아이디어를 직관적으로 이해하는 것이 목표입니다.\n",
        "\n",
        "---\n",
        "### 오늘 노트북에서 할 것\n",
        "1. 데이터셋 로딩 및 구조 확인\n",
        "2. 랜덤으로 예시 하나 뽑아서 `prompt / Answer A / Answer B` 읽어보기\n",
        "3. 내가 A/B 중 어느 쪽을 더 선호하는지 선택하기\n",
        "4. 데이터셋이 가진 정답(chosen)과 **내 선택의 일치율(agreement)** 계산하기\n",
        "5. 규칙 기반 `tiny_reward()` 함수를 정의해서, 각 답변에 점수를 매겨보기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 설치\n",
        "!pip install -q datasets pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imports"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['prompt', 'chosen', 'rejected'],\n",
            "    num_rows: 1638\n",
            "})\n",
            "컬럼: ['prompt', 'chosen', 'rejected']\n",
            "샘플 개수: 1638\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# dev7halo/naver-news-dpo 데이터셋 로딩, 다른 dpo 데이터셋도 유사한 방법으로 로딩 가능\n",
        "ds = load_dataset(\"dev7halo/naver-news-dpo\", split=\"train\")\n",
        "\n",
        "print(ds)\n",
        "print(\"컬럼:\", ds.column_names)\n",
        "print(\"샘플 개수:\", len(ds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 예시 한 개를 보기 좋게 출력하는 함수\n",
        "\n",
        "- `swap=False`이면 A=chosen, B=rejected\n",
        "- `swap=True`이면 A=rejected, B=chosen 으로 섞어서 보여줍니다.\n",
        "  - 이렇게 하면 항상 chosen이 A로 보이는 편향을 줄일 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "show_example"
      },
      "outputs": [],
      "source": [
        "def show_example(example, swap=False):\n",
        "    \"\"\"하나의 예시를 프롬프트와 함께 A/B 두 답변으로 출력합니다.\n",
        "\n",
        "    example: ds에서 뽑은 한 row (dict-like)\n",
        "    swap=False이면 A=chosen, B=rejected\n",
        "    swap=True이면 A=rejected, B=chosen\n",
        "\n",
        "    return: 데이터셋 기준으로 더 선호된 답이 어느 쪽(A/B)인지 라벨\n",
        "    \"\"\"\n",
        "    prompt = example[\"prompt\"]\n",
        "    chosen = example[\"chosen\"]\n",
        "    rejected = example[\"rejected\"]\n",
        "\n",
        "    if not swap:\n",
        "        answer_A = chosen\n",
        "        answer_B = rejected\n",
        "        correct_label = \"A\"   # 데이터셋이 선호한 쪽\n",
        "    else:\n",
        "        answer_A = rejected\n",
        "        answer_B = chosen\n",
        "        correct_label = \"B\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"[Prompt]\")\n",
        "    print(prompt.strip(), \"\\n\")\n",
        "\n",
        "    print(\"[Answer A]\")\n",
        "    print(answer_A.strip(), \"\\n\")\n",
        "\n",
        "    print(\"[Answer B]\")\n",
        "    print(answer_B.strip(), \"\\n\")\n",
        "\n",
        "    return correct_label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 인터랙티브 A/B 선호 선택\n",
        "\n",
        "아래 셀을 실행하면 여러 번의 **ROUND**가 진행됩니다.\n",
        "\n",
        "각 라운드에서:\n",
        "1. 프롬프트와 두 개의 답변 A/B가 출력됩니다.\n",
        "2. 여러분은 `A`, `B` 중 어느 쪽이 더 나은지 입력합니다.\n",
        "3. 데이터셋의 원래 선호(chosen)와 일치하는지 여부를 바로 확인할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "loop"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "############ ROUND 1 ############\n",
            "\n",
            "================================================================================\n",
            "[Prompt]\n",
            "주어진 기사 제목을 이용해 신문기사를 작성하세요. 기사 제목: 재창업 자금지원에도…5년후 좀비 수두룩 \n",
            "\n",
            "[Answer A]\n",
            "중진공 2016 2021년 지원 조사 3년후부터 70%가 고용성과 급감 매출도 초기 대비 10%로 떨어져 기업 단계별 지원 대책 마련 필요 서울경제 정부 자금을 제공 받고 재창업에 나섰던 기업 10곳 중 7곳 가량이 지원을 받은 지 3년 이후에는 고용 인원이 1명 이하로 떨어지는 것으로 나타났다. 이 기간 동안 휴·폐업 업체들이 속출하며 기업 전체 매출액도 지원 당시 대비 10% 수준으로 고꾸라졌다. 정부 지원을 발판 삼아 재도전에 나섰지만 ‘창업 데스밸리’를 넘지 못하고 현재 이름만 유지하는 기업들이 수두룩하다는 지적이 나온다. 정부 자금이 ‘밑 빠진 독에 물 붓기’가 되지 않으려면 후속 지원이 필요하다고 재도전 기업인들은 입을 모은다. 6일 더불어민주당 소속 이성만 의원실과 중소벤처기업진흥공단에 따르면 지난 2016년부터 총 4021곳이 재창업 자금 지원을 받았다. 재도전 지원에는 연간 1000억 1200억 원이 자금이 집행돼 지난 6년간 총 6600억원이 투입됐다. ‘실패 기업인’에게 1억 원 가량의 자금을 빌려주는 형식으로 거치 기간 3년을 두고 6년 이내에 대출을 상환하도록 한다. 연간 100억 원대가 집행되다 박근혜 정부 시절인 2016년부터 1000억대로 확대됐다. 지원 규모는 늘었지만 성과는 기대에 미치지 못하고 있다는 평가가 적지 않다. 실제 지난 2016년 지원 받은 기업 526곳 가운데 올 5월 기준 종업원 수가 하나도 없는 업체는 63.6% 335곳 에 달한다. 지원 당시 10 20여 명의 직원이 있었지만 현재 아무도 남아 있지 않는 회사가 상당수다. 아울러 현 종업원이 1명에 그치는 곳 또한 6.08% 32곳 로 집계된다. 고용 창출 능력이 희박한 곳이 69.8%에 달하는 셈으로 이 경우 사실상 폐업에 가깝다는 게 업계의 지배적인 해석이다. 다만 고용 실적이 기대에 미치지 못하다고 폐업으로 단정할 수 없다는 게 중진공의 설명이다. 2017년 지원 받은 기업 또한 사정은 매한가지다. 이 경우 현재 고용이 1명 이하인 업체는 약 67% 수준이다. 특히 자금 지원 후 3년이 되면서 성과는 급감했다. 2020년 및 2021년 지원 받은 업체 중 고용 실적이 떨어지는 곳은 약 43% 수준이지만 2019년 지원 기업부터 이 수치 75.7% 는 70 80%대로 높아지는 것은 이를 잘 드러낸다. 미진한 건 매출 성적도 마찬가지다. 2016년 지원 받은 기업의 당시 총 매출은 4026억 원이었지만 지난해 올린 매출은 417억원에 불과하다. 2017년 지원 기업 역시 매출액이 6339억원에서 지난해 1573억으로 줄었다. 2018년 지원 기업은 5555억원에서 599억원으로 떨어졌다. 그만큼 생존 환경이 녹록지 않다는 의미다. 다만 폐업 등을 감안해 기업별 평균 수치로 보면 가령 2016년 지원 업체의 경우 평균 매출이 13억원에서 현재 30억원으로 늘어난다. 중진공 관계자는 “대상기업수에 대한 고려 없이 단순 매출 총액만으로 비교하기에는 어렵다”고 말했다. 이렇다 보니 빌린 돈을 제때 갚지 못하는 곳들도 속출한다. 지난해에 발생한 중진공 재창업 자금의 불납결손액만 211억원에 이른다. 이는 현 제도가 초기 단계에 집중돼 있다는 점과 무관하지 않다고 재창업 기업인들은 지적한다. 초기 지원도 중요하지만 정작 회사 확장 시기에 더 많은 자금이 소요되는데 추가 지원이 제한되어 있어 사업을 본궤도에 올리지 못하고 접는다는 설명이다. 이에 보증기관을 통해 지원을 받으려는 시도가 많지만 과거 회생 도산 등 이력 때문에 자금 조달 과정에서 실패하는 사례들이 많다. 한 재도전 기업인은 “재창업 기업은 지원 후 3 5년 시기에 생존율이 급격하게 떨어진다”며 “2017년 재창업인을 대상으로 강원 태백에서 교육을 받은 적이 있는데 당시 참가했던 곳 30 40개 업체 중 현재 연락이 되는 업체는 10%에 불과하다”고 말했다. 그는 이어 “초기 자금 마련에도 불구하고 다른 기관에서 지원이 막혀 답답함을 느낄 때가 많다”고 했다. 중진공의 지원 기회 제한 방침도 논쟁의 대상으로 꼽힌다. 재원이 한정된 탓에 기회를 두루 넓게 제공한다는 의도로 현재는 지원 횟수를 제한한다. 지난 2019년 국회 국정감사에서 나온 지적에서 비롯됐다. 하지만 이 때문에 일각에선 정작 필요할 때 자금 경로가 막힌다는 반박도 있다. 국회 의사록을 보면 당시 이상직 중진공 이사장은 “중복 지원 문제는 양면이 있다”며 “중소기업을 한 단계 스케일업 하려면 지원해 줘야 된다”고 언급했지만 결국 제도를 현재와 같이 수정했다. \n",
            "\n",
            "[Answer B]\n",
            "【서울=뉴시스】김민지 기자 = 정부의 재창업 자금지원에도 불구하고, 5년 후에는 '좀비 기업'이 수두룩한 것으로 나타났다. \n",
            "\n",
            "더불어민주당 소속 이성만 의원실과 중소벤처기업진흥공단에 따르면, 서울경제 정부 자금을 제공받아 재창업에 나섰던 기업 10곳 중 7곳 가량이 지원을 받은 지 3년 이후에는 고용 인원이 1명 이하로 떨어지는 것으로 나타났다. 이 기간 동안 휴·폐업 업체들이 속출하며 기업 전체 매출액도 지원 당시 대비 10% 수준으로 급감했다.\n",
            "\n",
            "이성만 의원은 \"정부의 재창업 지원 정책이 실효성을 갖추지 못하고 있다\"며 \"지원을 받은 기업들이 장기적으로 성장하지 못하고, 오히려 경제적 부담을 가중시키는 결과를 초래하고 있다\"고 비판했다.\n",
            "\n",
            "정부는 재창업을 지원하기 위해 다양한 프로그램을 운영하고 있다. 재창업 자금지원은 창업 실패로 인해 경제적 어려움을 겪는 기업가들에게 재기의 기회를 제공하기 위한 목적으로 시작되었다. 그러나 이번 조사 결과는 이러한 정책의 한계를 명확히 보여주고 있다.\n",
            "\n",
            "재창업 기업들의 실패 원인으로는 경영 능력 부족, 시장 변화 대응 능력 부족, 자금 조달 어려움 등이 지적되고 있다. 특히, 재창업 지원금이 일시적인 자금난 해소에 그치고, 장기적인 경영 전략 수립이나 경쟁력 강화에 활용되지 못한 경우가 많았다는 지적이 제기되고 있다.\n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책의 개선이 시급하다\"며 \"기업가들의 경영 능력 향상과 시장 변화에 대한 대응 능력을 강화할 수 있는 교육 프로그램을 확대하고, 장기적인 성장을 위한 자금 지원 방안을 마련해야 한다\"고 강조했다.\n",
            "\n",
            "한편, 정부는 재창업 지원 정책의 효과를 높이기 위해 다양한 방안을 모색하고 있다. 이에 따라 재창업 지원금의 사용처를 더욱 구체화하고, 기업가들의 경영 역량 강화를 위한 교육 프로그램을 강화하는 방안이 검토되고 있다.\n",
            "\n",
            "재창업 지원 정책의 실효성을 높이기 위해서는 정부와 기업가들의 노력뿐만 아니라, 시장의 변화에 대한 빠른 대응과 혁신적인 아이디어가 필요하다. 정부는 이러한 측면을 고려하여 재창업 지원 정책을 지속적으로 개선해 나갈 계획이다.\n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책이 실패한 기업가들에게 새로운 희망을 줄 수 있도록 정부와 기업가들이 함께 노력해야 한다\"며 \"정부의 지원이 단순히 자금 지원에 그치지 않고, 기업가들의 성공적인 재기와 성장을 위한 종합적인 지원 체계를 구축해야 한다\"고 강조했다.\n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 개선 방안을 마련할 계획이다. 이를 통해 재창업 지원 정책이 실효성을 갖추고, 실패한 기업가들이 새로운 도전을 통해 성공적인 재기를 이룰 수 있도록 지원할 방침이다. \n",
            "\n",
            "이와 관련해 전문가들은 \"재창업 지원 정책의 성공을 위해서는 정부의 지원뿐만 아니라, 기업가들의 노력과 시장의 변화에 대한 빠른 대응이 필요하다\"며 \"기업가들이 시장 변화를 예측하고, 혁신적인 아이디어를 통해 경쟁력을 강화할 수 있도록 지원하는 것이 중요하다\"고 조언했다.\n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 개선 방안을 마련할 계획이다. 이를 통해 재창업 지원 정책이 실효성을 갖추고, 실패한 기업가들이 새로운 도전을 통해 성공적인 재기를 이룰 수 있도록 지원할 방침이다. \n",
            "\n",
            "재창업 지원 정책의 성공을 위해서는 정부와 기업가들의 노력뿐만 아니라, 시장의 변화에 대한 빠른 대응과 혁신적인 아이디어가 필요하다. 정부는 이러한 측면을 고려하여 재창업 지원 정책을 지속적으로 개선해 나갈 계획이다. \n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책이 실패한 기업가들에게 새로운 희망을 줄 수 있도록 정부와 기업가들이 함께 노력해야 한다\"며 \"정부의 지원이 단순히 자금 지원에 그치지 않고, 기업가들의 성공적인 재기와 성장을 위한 종합적인 지원 체계를 구축해야 한다\"고 강조했다.\n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 개선 방안을 마련할 계획이다. 이를 통해 재창업 지원 정책이 실효성을 갖추고, 실패한 기업가들이 새로운 도전을 통해 성공적인 재기를 이룰 수 있도록 지원할 방침이다. \n",
            "\n",
            "재창업 지원 정책의 성공을 위해서는 정부와 기업가들의 노력뿐만 아니라, 시장의 변화에 대한 빠른 대응과 혁신적인 아이디어가 필요하다. 정부는 이러한 측면을 고려하여 재창업 지원 정책을 지속적으로 개선해 나갈 계획이다. \n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책이 실패한 기업가들에게 새로운 희망을 줄 수 있도록 정부와 기업가들이 함께 노력해야 한다\"며 \"정부의 지원이 단순히 자금 지원에 그치지 않고, 기업가들의 성공적인 재기와 성장을 위한 종합적인 지원 체계를 구축해야 한다\"고 강조했다. \n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 개선 방안을 마련할 계획이다. 이를 통해 재창업 지원 정책이 실효성을 갖추고, 실패한 기업가들이 새로운 도전을 통해 성공적인 재기를 이룰 수 있도록 지원할 방침이다. \n",
            "\n",
            "재창업 지원 정책의 성공을 위해서는 정부와 기업가들의 노력뿐만 아니라, 시장의 변화에 대한 빠른 대응과 혁신적인 아이디어가 필요하다. 정부는 이러한 측면을 고려하여 재창업 지원 정책을 지속적으로 개선해 나갈 계획이다. \n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책이 실패한 기업가들에게 새로운 희망을 줄 수 있도록 정부와 기업가들이 함께 노력해야 한다\"며 \"정부의 지원이 단순히 자금 지원에 그치지 않고, 기업가들의 성공적인 재기와 성장을 위한 종합적인 지원 체계를 구축해야 한다\"고 강조했다. \n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 개선 방안을 마련할 계획이다. 이를 통해 재창업 지원 정책이 실효성을 갖추고, 실패한 기업가들이 새로운 도전을 통해 성공적인 재기를 이룰 수 있도록 지원할 방침이다. \n",
            "\n",
            "재창업 지원 정책의 성공을 위해서는 정부와 기업가들의 노력뿐만 아니라, 시장의 변화에 대한 빠른 대응과 혁신적인 아이디어가 필요하다. 정부는 이러한 측면을 고려하여 재창업 지원 정책을 지속적으로 개선해 나갈 계획이다. \n",
            "\n",
            "이성만 의원은 \"재창업 지원 정책이 실패한 기업가들에게 새로운 희망을 줄 수 있도록 정부와 기업가들이 함께 노력해야 한다\"며 \"정부의 지원이 단순히 자금 지원에 그치지 않고, 기업가들의 성공적인 재기와 성장을 위한 종합적인 지원 체계를 구축해야 한다\"고 강조했다. \n",
            "\n",
            "정부는 재창업 지원 정책의 성공을 위해 기업가들의 의견을 적극 수렴하고, 실패 원인을 철저히 분석하여 \n",
            "\n",
            "\n",
            "[결과] 데이터셋이 선호한 쪽: A, 나의 선택: A\n",
            "→ ✅ 나의 선택이 DPO preference와 일치합니다.\n",
            "\n",
            "\n",
            "############ ROUND 2 ############\n",
            "\n",
            "================================================================================\n",
            "[Prompt]\n",
            "주어진 문서를 길게 요약해주세요. 문서: 장우혁 CTO 망치 전문가 되기보다 건축가 꿈꿔라 모든 산업에서 디지털 전환이 이뤄지면서 ‘개발자’ 몸값은 그야말로 금값이 됐다. 높은 연봉과 인센티브 재택근무 보장과 스톡옵션을 제시하며 채용공고를 내지만 상대적으로 가난한 스타트업들은 큰 기업들의 개발자 싹쓸이에 속수무책일 수밖에 없다. 명품 플랫폼 캐치패션 역시 대중들에게는 생소한 스타트업이다. 명품 플랫폼 업계에서도 후발주자고 매출 규모에서 세 손가락 안에도 들지 못한다. 얼마 전에는 개발자들이 집단 퇴사하는 내홍까지 겪었다. 아무리 봐도 개발자를 유인할 뾰족한 수가 잘 보이지 않는다. 최근 “이런 곳에 왜 ”라는 질문이 저절로 드는 최고기술책임자 CTO 선임 소식이 캐치패션으로부터 들려왔다. 삼성전자 무선사업부 11번가 구글클라우드코리아 등에서 경험을 쌓은 장우혁 CTO를 회사의 개발 조직 수장으로 스카웃했다는 꽤 충격 적인 얘기였다. 장우혁 캐치패션 CTO 궁금했다. 잘 쌓은 과거의 경력을 비춰봤을 때 더 좋은 회사 소위 잘 나가는 기업에서 러브콜을 보낼 것 같은 그가 캐치패션을 선택한 이유가 뭘까 호기심이 일었다. 솔직히 “돈 때문이지 뭐”란 생각도 스쳐갔다. 그런데 그것만으로는 뭔가 부족해 보였다. 아닐 수도 있다는 기대감도 들었다. 우연찮게 인터뷰의 기회가 주어졌다. 지난 달 30일 논현동에 위치한 캐치패션에서 장우혁 CTO를 만났다. 장마에 접어들 무렵 비가 추적추적 내리는 날 그는 회사 현관문 앞에서 한 동료와 대화를 나누고 있었다. 같은 개발직군의 직원은 아닌 것 같았다. 얼핏 영어가 들렸는데 자세한 내용은 몰라도 주변과 편하게 소통한다는 인상을 받았다. 인터뷰 하기로 약속된 기자를 알아본 그는 직접 보안키로 문을 열더니 회의실 안으로 함께 걸어 들어왔다. 인터뷰 시작부터 가장 궁금했던 내용을 직설적으로 물었다. 더 좋은 회사를 선택하지 않고 도대체 왜 캐치패션에 왔냐는 질문이었다. 독자들 개발자 이 보면 다 티가 날 테니 최대한 솔직하게 말해달라는 주의사항도 첨언했다. 이에 대한 그의 답변은 캐치패션이 성공할 것 같았고 성공시켜보겠다는 자신의 열망이 너무나 컸기 때문으로 요약된다. 아직은 좀 형식적인 답변 같았다. 장우혁 CTO는 캐치패션 합류 전 내부적으로 뒤숭숭했던 개발 조직의 문제를 알고 있었다. 이 때문에 장 CTO는 이우창 대표가 자율성이 중시되는 개발 조직에 강성이어서 그런 게 아닐까 하는 생각도 했다. 하지만 무려 4시간 가까운 토론에서 장우혁 CTO는 자신의 생각과 달리 이 대표가 완전한 자율성을 준다는 사실을 깨달았다. 또 이 대표가 과거 유통 분야에서 쌓은 풍부한 현장 경험으로 사업에 진심으로 임한다는 것도 확인했다. 나아가 캐치패션이 당면한 문제에 기여할 수 있는 게 굉장히 많겠다는 생각에 캐치패션을 선택했다는 것이 장 CTO의 설명이다. “11번가에서 엔지니어의 꿈인 구글로 이직을 했어요. 구글클라우드 데이터 분석 전문가로 일하게 되면서 많은 기대를 품었고 글로벌 회사의 일하는 방식과 개발자들의 꿈인 브랜드에 편승하고픈 마음이 없지 않아 있었던 것도 사실이에요. 구글에서 코로나 때문에 재택으로 일하면서 고객사들이 데이터 플랫폼을 구축하고 AI 머신러닝 기술로 비즈니스 문제를 해결하는 데 역할을 했지만 점점 더 욕심이 생겼어요. 나의 문제를 풀지 않고 왜 남의 문제를 풀고 있지 하는 생각이 들 무렵 캐치패션으로부터 제안이 왔습니다.” 장우혁 CTO는 캐치패션에 합류한 뒤 시니어 개발자들을 삼성전자와 구글 쿠팡 출신들로 채웠다. 아직은 전체 조직이 5명 내외지만 근 시일 내에 10명 이상의 조직으로 키울 계획이다. 그러나 앞서 한 걱정처럼 개발자 채용은 계획대로 되지 않는다. 여러 기업들이 두 자릿수 세 자릿수 채용 공고를 내지만 이는 목표이지 결과가 아닌 경우가 많다. 캐치패션 광고 그래서 또 거칠게 물었다. 개발자들에게 캐치패션이 무엇을 줄 수 있는가. 전면 재택근무 높은 연봉 구글 못지않은 직원 복지 등...어떤 카드를 대체 쓸 수 있단 말인가. 그러자 장우혁 CTO는 “연봉이 높아지는 길을 보여주겠다”고 자신했다. 또 자신은 솔직히 재택근무보다는 한 곳에서 여러 부서와 소통하는 업무 방식을 선호한다고도 했다. 캐치패션에 관심을 보이려던 개발자들이 떠나는 소리가 속으로 들렸지만 다음 그의 말을 듣자 묘하게 설득됐다. “워라밸을 당장 챙기는 것보다 명확한 비즈니스 문제를 보여주고 스스로 풀도록 권한과 기회를 주는 것 그리고 이것이 숫자를 통해 경영 성과로 이어지도록 하는 것이 결국 개발자에 대한 최고의 복지라고 생각해요. 또 크게 성공한 개발자들은 비즈니스에 대한 깊은 이해를 갖고 있죠. 개발자는 건물을 짓는 건축가가 돼야지 망치 전문가가 돼서는 곤란해요. 캐치패션에 합류한다면 본인이 인정받고 꿈꾸는 건축물을 지을 수 있는 개발자가 되는 데 적극적인 도움을 드릴 계획입니다.” 그래도 부모님이 흡족해하실 만한 소위 ‘네카라쿠배’ 네이버·카카오·라인·쿠팡·배달의민족 에 취업하는 것이 내 커리어에 훨씬 득이 되는 것 아닐까. 장 CTO는 한편으로 인정하면서도 여전히 캐치패션 개발 조직의 강점을 분명히 제시하고 자신했다. 비즈니스 문제를 굉장히 포괄적으로 접할 수 있고 본인이 해결할 수 있다는 측면에서 그리고 그 과정에서 자신이 끌어주고 밀어주는 코치 역할을 하겠다고 약속했다. “저희 개발팀 구성은 업계 최고 수준이라 자신합니다. 개발자의 능력은 결국 학벌이나 어디 출신이 아니라 기술력을 바탕으로 한 납기일 내 완결성 소통 능력 작은 일이 주어져도 스스로 그 가치를 높이는 능력이에요. 톱 수준의 시니어 개발자들이 1 1 밀착 지도를 하면서도 본인 업무 중 그들이 집중하는 것만 체크하고 회사 일과 연계성을 점검하면서 그들의 성장을 도울 겁니다. 같이 업무 하면서 같은 목표로 서로에게 충실하면서 압축 성장할 수 있는 기회를 드리겠습니다.” 이력서에 내가 어떤 문제를 해결했고 이로 인해 회사의 실적이 이만큼 향상하는 데 기여했다는 짧지만 굵은 한줄 한줄을 채울 수 있도록 돕겠다는 것이 장 CTO의 약속이었다. 이 과정을 통해 실제로 동료들이 더 좋은 곳으로 이직하는 것을 보게 됐을 때 개발자 스스로 문제에 대한 주인의식을 가질 수 있다는 설명도 했다. 회사에 충실하게 되는 것이 아니라 본인 문제와 이력에 주인의식을 갖도록 한다는 것이 그의 철학이다. 장우혁 캐치패션 CTO2 그가 캐치패션에 온 이유 개발 조직과 문화에 대한 그의 생각은 여기까지. 앞으로 그가 캐치패션에서 풀고 싶은 문제를 들어볼 차례였다. 캐치패션은 ‘럭셔리 애그리게이터 플랫폼’을 지향한다. 애그리게이터란 여러 회사의 상품이나 서비스에 대한 정보를 수집하고 분류해 고객들이 검색과 비교를 용이하게 하는 서비스를 뜻한다. 캐치패션은 글로벌 파트너십을 기반으로 100% 정품만을 취급하며 각 상품 정보를 실시간 연동하고 있다. 총 400만여 개의 다양한 상품들이 검색되고 실시간 가격 비교가 이뤄지며 재고 확인도 된다. 할인 혜택을 한 곳에 모아볼 수도 있다. 장우혁 CTO는 앞으로 캐치패션의 카테고리를 보다 생활 밀착형으로 다양화 한다는 계획이다. ‘명품’이라는 단어에 걸맞는 고객 최적화 서비스를 구축한다는 것. 현재 캐치패션은 명품 패션에 주력하고 있지만 향후에는 리빙 키즈 여행 숙소 그림 등으로 확대하는 그림을 그리고 있다. 보다 많은 사람들이 일상에서 품질 높은 서비스를 경험하도록 하기 위한 여러 노력들을 기울일 예정이다. 이를 위한 콘텐츠 강화 빠른 고객사 확보에 주력할 방침이다. 나아가 국내에 품질 좋은 오리지널 상품들을 판매하는 소규모 브랜드들을 발굴하고 이들의 성장을 도우면서 글로벌 시장에 진출한다는 구상도 갖고 있다. “캐치패션에 입점하길 원하는 좋은 파트너사들이 많은데 생각만큼 쉽지 않은 작업이에요. API 연동 정책 문제 셋업 등 여러 부서들이 오케스트라처럼 협업해야 하기 때문이죠. 개발 조직은 현재 여기에 소요되는 노력과 시간들을 단축하는 시스템 설계를 하고 있습니다.” 끝으로 장우혁 CTO는 캐치패션의 강점 중 하나로 부서 간 소통 능력을 강조했다. 마케팅 경영 개발 고객응대 등 모든 조직이 서로 열린 자세로 대화를 주고받는 데 큰 힘을 지녔다고 설명했다. 한마디로 마음에 맞는 구성원들로 채워졌다는 것이다. 이 때문에 캐치패션의 빠른 성장을 자신했다. “애자일 방식 개발과 함께 즉시 피드백을 받아서 유동적으로 개발하는 방법 으로 굉장히 신명나게 일하는 방식을 채택하고 있어요. 시리즈 B 단계의 스타트업이 마음 맞는 구성원들로 채워지면 눈 깜짝할 사이에 성장해요. 이 로켓에 좋은 분들이 빨리 합류하셨으면 좋겠습니다.” 망치 전문가가 아닌 ‘건축가’가 되기를 희망하는 개발자들에게 캐치패션이 안성맞춤이란 말이 기억에 남았다. 또 회사가 아닌 개발자들이 이직했을 때 확실한 경력으로 인정받고 더 높은 연봉을 받을 수 있도록 돕겠다는 그의 약속이 다시 한 번 떠올랐다. 뻔한 임기응변이 아니라 진정성이 느껴졌다는 점에서 캐치패션의 성장을 좀 더 오래 지켜보고 싶다는 생각이 든 인터뷰였다. \n",
            "\n",
            "[Answer A]\n",
            "장우혁 CTO는 캐치패션에 합류한 이유로, 캐치패션이 성공할 가능성이 높다고 판단했고, 그 성공에 기여하고 싶은 열망이 컸다고 말했습니다. 그는 이우창 대표와의 4시간 가까운 토론을 통해 이 대표가 개발 조직에 완전한 자율성을 부여하고, 사업에 진심으로 임한다는 것을 확인했습니다. 또한, 캐치패션이 당면한 문제에 기여할 수 있는 부분이 많다고 판단해 합류를 결정했습니다.\n",
            "\n",
            "장우혁 CTO는 캐치패션에서 개발자들에게 높은 연봉과 전면 재택근무, 구글 못지 않은 직원 복지를 제공하겠다는 계획을 제시했습니다. 그러나 그는 개발자들에게 단순히 워라밸을 챙기는 것보다 명확한 비즈니스 문제를 제시하고, 이를 해결할 권한과 기회를 주는 것이 최고의 복지라고 강조했습니다. 그는 개발자가 단순한 '망치 전문가'가 아닌 '건축가'가 되어야 한다고 주장하며, 캐치패션에서 개발자들이 비즈니스에 대한 깊은 이해를 갖출 수 있는 기회를 제공할 계획이라고 밝혔습니다.\n",
            "\n",
            "장우혁 CTO는 캐치패션의 개발팀 구성이 업계 최고 수준이라고 자신하며, 시니어 개발자들이 1:1 밀착 지도를 통해 개발자들의 성장을 돕겠다고 약속했습니다. 그는 개발자들이 실제 업무를 통해 문제 해결 능력을 키우고, 이력서에 자신이 해결한 문제와 그 결과를 명확히 기재할 수 있도록 지원할 계획이라고 말했습니다.\n",
            "\n",
            "캐치패션은 '럭셔리 애그리게이터 플랫폼'을 지향하며, 다양한 명품 상품 정보를 실시간으로 제공하고 있습니다. 장우혁 CTO는 앞으로 캐치패션의 카테고리를 생활 밀착형으로 다양화하고, 명품 패션 외에도 리빙, 키즈, 여행, 숙소, 그림 등으로 확대할 계획이라고 밝혔습니다. 이를 통해 보다 많은 사람들이 일상에서 품질 높은 서비스를 경험할 수 있도록 하겠다는 목표를 세웠습니다.\n",
            "\n",
            "장우혁 CTO는 캐치패션의 강점 중 하나로 부서 간 소통 능력을 강조하며, 모든 조직이 열린 자세로 대화를 주고받는 문화를 소개했습니다. 그는 애자일 방식의 개발과 즉시 피드백을 받아 유동적으로 개발하는 방식으로 빠른 성장을 이룰 수 있다고 자신했습니다. 그는 캐치패션의 성장을 위해 좋은 인재들이 빠르게 합류하기를 바라고 있다고 말했습니다. [/INST] \n",
            "\n",
            "[Answer B]\n",
            "삼성·구글 출신 시니어 개발자가 ‘캐치패션’에 합류한 이유 \n",
            "\n",
            "\n",
            "[결과] 데이터셋이 선호한 쪽: A, 나의 선택: A\n",
            "→ ✅ 나의 선택이 DPO preference와 일치합니다.\n",
            "\n",
            "\n",
            "############ ROUND 3 ############\n",
            "\n",
            "================================================================================\n",
            "[Prompt]\n",
            "주어진 문서를 길게 요약해주세요. 문서: 편집자주 차이 나는 중국을 불편부당한 시선으로 바라봅니다. 사진 블룸버그 6월 폭락장에서 소리없이 상승한 상장지수펀드 ETF 가 있다. 국내 모 자산운용사가 출시한 차이나전기차SOLACTIVE 다. 이 ETF는 중국의 제로코로나 정책과 상하이 봉쇄로 4월말 1만원대까지 급락했지만 5월 이후 중국 전기차 관련주가 급등하며 지난 28일 1만8000원대를 터치하는 등 초강세를 보였다. 거래대금도 테마형 ETF 치고는 상당해서 2000억원을 넘은 날도 많다. 그런데 앞으로는 국내 투자자들이 국내 자산운용사가 출시한 중국ETF가 아니라 중국 자산운용사들이 만든 ETF에 직접 투자할 수 있게 된다. 다만 해외상장 ETF는 매매차익 중 250만원을 공제한 금액에 대해 22%의 양도소득세가 부과되며 국내상장 해외ETF는 매매차익에 대해 15.4%의 배당소득세가 부과되는 등 세제가 다른 점은 유의해야 할 대목이다. start block ━ 후강퉁 선강퉁을 거쳐 중국 ETF 시장 개방 ━ end block 지난달 28일 저녁 중국 증권감독관리위원회 CSRC 홍콩 증권선물위원회 SFC 는 오는 4일 내일 부터 상장지수펀드 ETF 가 중국 상하이·선전거래소와 홍콩거래소 간 교차거래인 후강퉁과 선강퉁 거래 대상에 포함된다고 밝혔다. 중국 본토 증시 개방이 개별 종목에서 ETF까지 확대되면서 중국 증시 투자 옵션이 다양해지게 되는 셈인데 중국 자본시장에도 적잖은 변화를 가져올 것으로 보인다. 중국 A주 본토 시장 개방에 있어서 가장 큰 이정표는 2014년 11월부터 시행된 중국 상하이거래소와 홍콩거래소간 교차거래인 후강퉁이다. 그전까지는 적격외국인기관투자가 QFII·Qualified Foreign Institutional Investor 자격을 취득한 글로벌 금융기관만 중국 주식에 투자할 수 있었지만 후강퉁 시행으로 개인 투자자도 중국 본토 A주 시장에 투자할 수 있게 됐다. 중국 증시 시가총액 1위인 바이주업체 마오타이 2위 공상은행 3위 건설은행 4위 차이나모바일 등 대형 국유기업은 주로 상하이거래소에 상장돼 있다. 중국 금융당국은 대형주 위주인 상하이거래소를 먼저 개방해서 시장을 테스트한 다음 2016년 12월에는 중소형주가 주로 상장된 선전거래소와 홍콩거래소간 교차거래인 선강퉁을 시행하며 개방 범위를 넓혔다. 2014년 11월 후강퉁과 2016년 12월 선강퉁 시행 이후 지난 5월말까지 중국 홍콩간 교차거래를 통해 중국 증시로 유입된 외국인투자자의 순매수금액은 1조6334억 위안 약 310조원 에 달하는 것으로 나타났다. 또한 같은 기간 중국 투자자들이 홍콩거래소 상장종목을 순매수한 금액도 2조98억 위안 약 382조원 에 달했다. 중국 투자자들은 홍콩증시에 상장된 중국 인터넷주식을 주로 매수한 것으로 나타났다. start block ━ 빠르게 성장 중인 중국 ETF 시장 ━ end block 이번 ETF 시장 개방은 2016년 12월 선강퉁 시행 이후 거의 6년 만에 이뤄지는 대규모 시장개방이다. 특히 시장 개방대상이 개별종목에서 ETF로 확대된 게 특징이다. 중국 ETF 시장을 한번 살펴보자. 지난 4월 10일 중국 선전거래소가 발간한 ETF업종발전 연도보고서 에 따르면 2021년 말 기준 중국 금융시장에서 거래되는 전체 ETF 수량은 629개 전체 ETF 규모는 1조4046억 위안 약 267조원 에 달한다. 2012년 대비 ETF 수량은 약 15배 규모는 약 10배 증가했으며 특히 2020년부터 성장속도가 빨라지고 있다. ETF는 펀드와 달리 증권사 모바일트레이딩시스템 MTS 을 통해서 일반 종목처럼 매매할 수 있고 수수료도 저렴하기 때문에 중국에서도 갈수록 거래가 늘고 있다. ETF 종류별로 보면 629개 지난해 말 기준 상품 중 국내주식형 ETF가 520개로 82.7%를 차지했으며 그 뒤로 해외주식형 52개 통화 27개 상품 15개 채권 15개 순이었다. ETF 시장이 중국 국내주식형 위주로 발전하고 있음을 알 수 있다. 자산규모도 국내주식형 ETF가 9472억 위안 약 180조원 으로 약 3분의 2를 차지했다. start block ━ 전기차 희토류 등 83개 ETF가 외국인 투자자에게 개방 ━ end block 오는 4일부터 당장 거래가 가능한 ETF는 어떤 게 있을까 일단 기준부터 살펴보자. 중국 홍콩간 교차거래에 포함되는 중국주식 ETF는 지난 6개월간 일평균 자산규모가 15억 위안 약 2850억원 이상이어야 하며 편입종목은 후강퉁 선강퉁 대상 종목 위주여야 한다. 외국인 투자자가 매수할 수 있는 중국주식 ETF는 모두 83개이며 상하이거래소에 상장된 ETF가 53개 선전거래소에 상장된 ETF가 30개다. 지난해 말 기준 520개의 국내주식형 ETF와 비교하면 개방되는 ETF 수량은 크게 적지만 83개 개방 규모는 약 6000억 위안 약 114조원 으로 전체의 60%가 넘는다. 상하이거래소에 상장된 ETF는 주로 50 ETF 180 ETF 300 ETF 등 우량주 위주의 지수추종형이 많으며 금융 증권 비철금속 등 테마형 ETF도 일부 상장돼 있다. 참 희토류는 전 세계적으로 매장량이 적고 중국 의존도가 높은데 이번에 개방되는 ETF 중에는 희토류 ETF도 있다. 요즘 중국에서 한참 인기를 끌고 있는 전기차 배터리 인공지능 등 첨단산업 ETF를 매수할 수 있는 곳은 선전거래소다. 중국 1위 전기차업체 BYD 글로벌 최대 배터리업체 CATL 등 기술주가 주로 선전거래소에 상장돼 있기 때문에 기술테마 ETF도 선전거래소에서 많이 거래된다. 중국 ETF 시장이 개방되면 앞으로 전기차 배터리 반도체 인공지능 등 중국 첨단산업의 성장과실을 국내 투자자들도 함께 누리기가 쉬워질 것으로 보인다. 미국뿐 아니라 중국도 투자 대상으로 관심을 가질 필요가 있다. \n",
            "\n",
            "[Answer A]\n",
            "중국 투자자들이 국내 자산운용사가 출시한 중국ETF가 아니라 중국 자산운용사들이 만든 ETF에 직접 투자할 수 있게 되는데, 다만 해외상장 ETF는 매매차익 중 250만원을 공제한 금액에 대해 22%의 양도소득세가 부과되며 국내상장 해외ETF는 매매차익에 대해 15.4%의 배당소득세가 부과되는 등 세제가 다른 점은 유의해야 할 대목이며, 중국 본토 증시 개방이 개별 종목에서 ETF까지 확대되면서 중국 증시 투자 옵션이 다양해지게 되는 셈인데 중국 자본시장에도 적잖은 변화를 가져올 것으로 보인다. \n",
            "\n",
            "[Answer B]\n",
            "주어진 문장들을 바탕으로 다음과 같이 길게 요약하였습니다:\n",
            "\n",
            "편집자주: 중국을 불편부당한 시선으로 바라봅니다. 사진: 블룸버그\n",
            "\n",
            "6월 폭락장에서 상승한 상장지수펀드(ETF)가 있다. 국내 모 자산운용사가 출시한 '차이나전기차SOLACTIVE' ETF는 중국의 제로코로나 정책과 상하이 봉쇄로 4월 말 1만원대까지 급락했지만, 5월 이후 중국 전기차 관련주가 급등하며 6월 28일 1만8000원대를 돌파하며 초강세를 보였다. 거래대금도 테마형 ETF 치고는 상당하여 2000억원을 넘은 날도 많았다.\n",
            "\n",
            "앞으로는 국내 투자자들이 국내 자산운용사가 출시한 중국 ETF뿐만 아니라 중국 자산운용사가 만든 ETF에 직접 투자할 수 있게 된다. 그러나 해외상장 ETF는 매매차익 중 250만원을 공제한 금액에 대해 22%의 양도소득세가 부과되며, 국내상장 해외 ETF는 매매차익에 대해 15.4%의 배당소득세가 부과되는 등 세제가 다르므로 유의해야 한다.\n",
            "\n",
            "지난 6월 28일 저녁, 중국 증권감독관리위원회(CSRC)와 홍콩 증권선물위원회(SFC)는 7월 4일부터 상장지수펀드(ETF)가 중국 상하이·선전거래소와 홍콩거래소 간 교차거래인 후강퉁과 선강퉁 거래 대상에 포함된다고 발표했다. 이로써 중국 본토 증시 개방이 개별 종목에서 ETF까지 확대되면서 중국 증시 투자 옵션이 다양해졌다. 중국 자본시장에도 적지 않은 변화가 예상된다.\n",
            "\n",
            "중국 A주 본토 시장 개방의 가장 큰 이정표는 2014년 11월부터 시행된 중국 상하이거래소와 홍콩거래소 간 교차거래인 후강퉁이다. 이전에는 QFII(Qualified Foreign Institutional Investor) 자격을 취득한 글로벌 금융기관만 중국 주식에 투자할 수 있었지만, 후강퉁 시행으로 개인 투자자도 중국 본토 A주 시장에 투자할 수 있게 되었다. 중국 증시 시가총액 1위인 마오타이, 2위 공상은행, 3위 건설은행, 4위 차이나모바일 등 대형 국유기업은 주로 상하이거래소에 상장되어 있다. 중국 금융당국은 대형주 위주인 상하이거래소를 먼저 개방하여 시장을 테스트한 후, 2016년 12월에는 중소형주가 주로 상장된 선전거래소와 홍콩거래소 간 교차거래인 선강퉁을 시행하여 개방 범위를 넓혔다.\n",
            "\n",
            "2014년 11월 후강퉁과 2016년 12월 선강퉁 시행 이후, 2022년 5월 말까지 중국-홍콩 간 교차거래를 통해 중국 증시로 유입된 외국인 투자자의 순매수 금액은 1조6334억 위안(약 310조원)에 달했으며, 같은 기간 중국 투자자들이 홍콩거래소 상장 종목을 순매수한 금액도 2조98억 위안(약 382조원)에 달했다. 중국 투자자들은 주로 홍콩증시에 상장된 중국 인터넷주식을 매수한 것으로 나타났다.\n",
            "\n",
            "이번 ETF 시장 개방은 2016년 12월 선강퉁 시행 이후 거의 6년 만에 이뤄지는 대규모 시장 개방으로, 특히 시장 개방 대상이 개별 종목에서 ETF로 확대된 것이 특징이다. 2021년 말 기준 중국 금융시장에서 거래되는 전체 ETF 수량은 629개, 전체 ETF 규모는 1조4046억 위안(약 267조원)에 달한다. 2012년 대비 ETF 수량은 약 15배, 규모는 약 10배 증가했으며, 특히 2020년부터 성장 속도가 빨라지고 있다. ETF는 펀드와 달리 증권사 모바일 트레이딩 시스템(MTS)을 통해 일반 종목처럼 매매할 수 있고 수수료도 저렴하여 중국에서도 거래가 늘고 있다.\n",
            "\n",
            "ETF 종류별로 보면, 629개(2021년 말 기준) 상품 중 국내주식형 ETF가 520개로 82.7%를 차지했으며, 그 뒤로 해외주식형 52개, 통화 27개, 상품 15개, 채권 15개 순이었다. ETF 시장이 중국 국내주식형 위주로 발전하고 있음을 알 수 있다. 자산 규모도 국내주식형 ETF가 9472억 위안(약 180조원)으로 약 3분의 2를 차지했다.\n",
            "\n",
            "7월 4일부터 거래가 가능한 ETF는 어떤 것들이 있을까? 기준부터 살펴보면, 중국-홍콩 간 교차거래에 포함되는 중국 주식 ETF는 지난 6개월간 일평균 자산 규모가 15억 위안(약 2850억원) 이상이어야 하며, 편입 종목은 후강퉁, 선강퉁 대상 종목 위주여야 한다. 외국인 투자자가 매수할 수 있는 중국 주식 ETF는 모두 83개로, 상하이거래소에 상장된 ETF가 53개, 선전거래소에 상장된 ETF가 30개다. 2021년 말 기준 520개의 국내주식형 ETF와 비교하면 개방되는 ETF 수량은 크게 적지만, 83개 개방 규모는 약 6000억 위안(약 114조원)으로 전체의 60%가 넘는다.\n",
            "\n",
            "상하이거래소에 상장된 ETF는 주로 50 ETF, 180 ETF, 300 ETF 등 우량주 위주의 지수 추종형이 많으며, 금융, 증권, 비철금속 등 테마형 ETF도 일부 상장되어 있다. 희토류는 전 세계적으로 매장량이 적고 중국 의존도가 높은 자원으로, 이번에 개방되는 ETF 중에는 희토류 ETF도 포함되어 있다. 요즘 중국에서 인기를 끌고 있는 전기차, 배터리, 인공지능 등 첨단산업 ETF를 매수할 수 있는 곳은 선전거래소다. 중국 1위 전기차 업체 BYD, 글로벌 최대 배터리 업체 CATL 등 기술주가 주로 선전거래소에 상장되어 있기 때문에 기술테마 ETF도 선전거래소에서 많이 거래된다.\n",
            "\n",
            "중국 ETF 시장이 개방되면 앞으로 전기차, 배터리, 반도체, 인공지능 등 중국 첨단산업의 성장과실을 국내 투자자들도 함께 누리기가 쉬워질 것으로 보인다. 미국뿐 아니라 중국도 투자 대상으로 관심을 가질 필요가 있다.[/INST] \n",
            "\n",
            "\n",
            "[결과] 데이터셋이 선호한 쪽: B, 나의 선택: A\n",
            "→ ❌ 나의 선택이 DPO preference와 다릅니다.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    num_rounds = int(input(\"몇 번 정도 비교해볼까요? (예: 5): \").strip() or \"5\")\n",
        "except ValueError:\n",
        "    num_rounds = 5\n",
        "    print(\"정수가 아니어서 기본값 5로 설정합니다.\")\n",
        "\n",
        "results = []  # 각 라운드 결과 기록용\n",
        "\n",
        "for round_idx in range(1, num_rounds + 1):\n",
        "    print(f\"\\n\\n############ ROUND {round_idx} ############\\n\")\n",
        "\n",
        "    # 무작위 예시 하나 선택\n",
        "    ex = ds[random.randint(0, len(ds)-1)]\n",
        "\n",
        "    # A/B 순서를 랜덤하게 섞어서 보여준다 (편향 방지)\n",
        "    swap = random.random() < 0.5\n",
        "    correct_label = show_example(ex, swap=swap)\n",
        "\n",
        "    # 사용자 입력 받기\n",
        "    while True:\n",
        "        user_choice = input(\"당신이 더 선호하는 답은? (A/B, 건너뛰기: S): \").strip().upper()\n",
        "        if user_choice in [\"A\", \"B\", \"S\"]:\n",
        "            break\n",
        "        print(\"A, B, S 중 하나를 입력해주세요.\")\n",
        "\n",
        "    if user_choice == \"S\":\n",
        "        print(\"이 라운드는 건너뜁니다.\")\n",
        "        continue\n",
        "\n",
        "    # 기록\n",
        "    agree = (user_choice == correct_label)\n",
        "\n",
        "    # 현재 A/B에 실제로 어떤 텍스트가 들어갔는지도 기록해 둡니다.\n",
        "    if not swap:\n",
        "        answer_A = ex[\"chosen\"]\n",
        "        answer_B = ex[\"rejected\"]\n",
        "    else:\n",
        "        answer_A = ex[\"rejected\"]\n",
        "        answer_B = ex[\"chosen\"]\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "            \"round\": round_idx,\n",
        "            \"prompt\": ex[\"prompt\"],\n",
        "            \"answer_A\": answer_A,\n",
        "            \"answer_B\": answer_B,\n",
        "            \"dataset_preferred\": correct_label,  # DPO 기준 더 선호된 쪽(A/B)\n",
        "            \"my_choice\": user_choice,\n",
        "            \"agree_with_dataset\": agree,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"\\n[결과] 데이터셋이 선호한 쪽: {correct_label}, 나의 선택: {user_choice}\")\n",
        "    if agree:\n",
        "        print(\"→ ✅ 나의 선택이 DPO preference와 일치합니다.\")\n",
        "    else:\n",
        "        print(\"→ ❌ 나의 선택이 DPO preference와 다릅니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 선택 결과 요약 보기\n",
        "\n",
        "여기서는 지금까지의 라운드에서:\n",
        "- 내가 선택한 답(my_choice)\n",
        "- 데이터셋 기준 선호(dataset_preferred)\n",
        "- 둘이 일치하는지 여부(agree_with_dataset)\n",
        "를 표로 정리하고, **agreement rate** 를 계산합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "summary"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>round</th>\n",
              "      <th>dataset_preferred</th>\n",
              "      <th>my_choice</th>\n",
              "      <th>agree_with_dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>A</td>\n",
              "      <td>A</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B</td>\n",
              "      <td>A</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   round dataset_preferred my_choice  agree_with_dataset\n",
              "0      1                 A         A                True\n",
              "1      2                 A         A                True\n",
              "2      3                 B         A               False"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 나의 선택과 DPO 데이터셋의 선호(chosen)가 일치한 비율: 66.67%\n",
            "\n",
            "내가 더 자주 고른 답 (A/B):\n",
            "my_choice\n",
            "A    3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if len(results) == 0:\n",
        "    print(\"기록된 라운드가 없습니다. 위 셀을 다시 실행해보세요.\")\n",
        "else:\n",
        "    df = pd.DataFrame(results)\n",
        "    display(df[[\"round\", \"dataset_preferred\", \"my_choice\", \"agree_with_dataset\"]])\n",
        "\n",
        "    agreement_rate = df[\"agree_with_dataset\"].mean()\n",
        "    print(f\"\\n📊 나의 선택과 DPO 데이터셋의 선호(chosen)가 일치한 비율: {agreement_rate:.2%}\")\n",
        "\n",
        "    print(\"\\n내가 더 자주 고른 답 (A/B):\")\n",
        "    print(df[\"my_choice\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 규칙 기반 tiny_reward 함수로 점수 매겨보기\n",
        "\n",
        "이제 아주 단순한 규칙 기반 보상 함수를 하나 만들어서,\n",
        "`answer_A`, `answer_B` 에 점수를 매겨보고,\n",
        "우리의 규칙 기반 보상 함수가 사람/데이터셋의 선호와 얼마나 일치하는지도 확인해봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tiny_reward_def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tiny_reward 함수 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# 아주 단순한 규칙 기반 '보상함수' 예시\n",
        "positive_keywords = [\"추천\", \"도움\", \"도움이 될\", \"좋습니다\", \"좋아요\", \"권장\"]\n",
        "detail_keywords = [\"요약\", \"핵심\", \"정리\", \"설명\", \"자세히\"]\n",
        "\n",
        "negative_keywords = [\"그냥\", \"막\", \"대충\", \"상관없다\"]\n",
        "risky_keywords = [\"폭발물\", \"마약\", \"죽여\", \"테러\"]  # 이 데이터셋에는 거의 없겠지만 예시로 둠\n",
        "\n",
        "def tiny_reward(text: str) -> float:\n",
        "    \"\"\"규칙 기반 보상 함수 예시.\n",
        "    실제 RLHF의 보상모델은 이런 기준을 신경망이 직접 학습하는 버전이라고 볼 수 있습니다.\n",
        "    \"\"\"\n",
        "    score = 0.0\n",
        "\n",
        "    # 긍정/상세 표현에 가산점\n",
        "    if any(kw in text for kw in positive_keywords):\n",
        "        score += 1.0\n",
        "    if any(kw in text for kw in detail_keywords):\n",
        "        score += 0.5\n",
        "\n",
        "    # 부정/무책임 표현에 감점\n",
        "    if any(kw in text for kw in negative_keywords):\n",
        "        score -= 0.5\n",
        "    if any(kw in text for kw in risky_keywords):\n",
        "        score -= 2.0\n",
        "\n",
        "    # 너무 짧으면 약간 감점\n",
        "    if len(text) < 40:\n",
        "        score -= 0.5\n",
        "\n",
        "    return score\n",
        "\n",
        "print(\"tiny_reward 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiny_reward_apply"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최근 라운드 몇 개에 대해 tiny_reward 점수 비교:\n",
            "\n",
            "=== Round 1 ===\n",
            "dataset_preferred: A\n",
            "my_choice: A\n",
            "tiny_reward(A): 0.0\n",
            "tiny_reward(B): 0.0\n",
            "tiny_reward 기준으로 더 좋은 쪽: tie\n",
            "→ 규칙 기반 보상함수와 DPO 선호가 다릅니다.\n",
            "\n",
            "=== Round 2 ===\n",
            "dataset_preferred: A\n",
            "my_choice: A\n",
            "tiny_reward(A): 0.0\n",
            "tiny_reward(B): -0.5\n",
            "tiny_reward 기준으로 더 좋은 쪽: A\n",
            "→ 규칙 기반 보상함수와 DPO 선호가 일치합니다.\n",
            "\n",
            "=== Round 3 ===\n",
            "dataset_preferred: B\n",
            "my_choice: A\n",
            "tiny_reward(A): 0.0\n",
            "tiny_reward(B): 0.5\n",
            "tiny_reward 기준으로 더 좋은 쪽: B\n",
            "→ 규칙 기반 보상함수와 DPO 선호가 일치합니다.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "if len(results) == 0:\n",
        "    print(\"먼저 위의 인터랙티브 실습을 진행해주세요.\")\n",
        "else:\n",
        "    print(\"최근 라운드 몇 개에 대해 tiny_reward 점수 비교:\")\n",
        "\n",
        "    for _, row in df.tail(5).iterrows():\n",
        "        ra = tiny_reward(row[\"answer_A\"])\n",
        "        rb = tiny_reward(row[\"answer_B\"])\n",
        "        print(\"\\n=== Round\", row[\"round\"], \"===\")\n",
        "        print(\"dataset_preferred:\", row[\"dataset_preferred\"])\n",
        "        print(\"my_choice:\", row[\"my_choice\"])\n",
        "        print(\"tiny_reward(A):\", ra)\n",
        "        print(\"tiny_reward(B):\", rb)\n",
        "        better = \"A\" if ra > rb else \"B\" if rb > ra else \"tie\"\n",
        "        print(\"tiny_reward 기준으로 더 좋은 쪽:\", better)\n",
        "        \n",
        "        if better == row[\"dataset_preferred\"]:\n",
        "            print(\"→ 규칙 기반 보상함수와 DPO 선호가 일치합니다.\")\n",
        "        else:\n",
        "            print(\"→ 규칙 기반 보상함수와 DPO 선호가 다릅니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 마무리\n",
        "\n",
        "- `dev7halo/naver-news-dpo` 는 실제 DPO/선호 학습에 사용 가능한 형태의 데이터셋입니다.\n",
        "- 우리는 여기서 **prompt + (chosen, rejected)** 구조를 보고,\n",
        "  - A/B 중 어느 쪽을 더 선호하는지 직접 선택해 보았습니다.\n",
        "  - 나의 선택과 데이터셋의 `chosen` 이 얼마나 일치하는지 확인했습니다.\n",
        "- 또한 아주 단순한 규칙 기반 `tiny_reward()` 를 정의해서,\n",
        "  - 텍스트에 점수를 매기고,\n",
        "  - 이 점수가 DPO 선호와 얼마나 일치하는지 살펴보았습니다.\n",
        "\n",
        "실제 RLHF / Reward Model 학습에서는,\n",
        "\n",
        "> 이런 선호 데이터(Preference)를 대규모로 모으고,\n",
        "> 신경망을 이용해 **보상 함수를 근사**한 다음,\n",
        "> 그 보상 함수를 기준으로 LLM의 파라미터를 업데이트합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c66627c",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "3-3_naver_dpo_reward_demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hret",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
